# DashTable：增量扩容的高性能哈希表

> 哈希表是 Redis 的核心数据结构——所有键值对都存储在哈希表中。Redis 使用链地址法哈希表，扩容时需要渐进式 rehash。NanoRedis 采用了 Extendible Hashing（可扩展哈希），实现了真正的增量扩容——每次只分裂一个 segment，不影响其他数据。

## 1. 为什么不用标准哈希表？

### 1.1 Redis 的 rehash 问题

Redis 使用两个哈希表 `ht[0]` 和 `ht[1]` 进行渐进式 rehash：

```
扩容前:
  ht[0]: [bucket0] [bucket1] [bucket2] [bucket3]
  ht[1]: (空)

扩容触发:
  ht[1]: [bucket0] [bucket1] [bucket2] [bucket3] [bucket4] [bucket5] [bucket6] [bucket7]

渐进式 rehash:
  每次操作时，将 ht[0] 的一个 bucket 迁移到 ht[1]
  期间查找需要查两个表 ← 性能下降
  完成后交换 ht[0] 和 ht[1]
```

**问题**：
- 扩容期间需要维护两个表，内存翻倍
- 查找需要查两个表，增加延迟
- 大表扩容期间持续较长时间

### 1.2 DashTable 的方案

DashTable 使用 Extendible Hashing，将数据分散在多个小的 segment 中：

```
扩容前:
  Directory: [seg0] [seg1] [seg2] [seg3]

扩容时（只有 seg1 满了）:
  只分裂 seg1 → seg1a + seg1b
  其他 segment 完全不受影响

  Directory: [seg0] [seg1a] [seg2] [seg3] ... [seg1b] ...
```

每次扩容只涉及一个 segment（通常几十到几百个元素），扩容延迟可预测且极低。

## 2. Extendible Hashing 原理

### 2.1 核心概念

Extendible Hashing 由两层结构组成：

```
                    Directory（目录）
                    ┌───────────────┐
                    │ global_depth=3│
                    ├───┬───┬───┬───┤───┬───┬───┬───┐
                    │ 0 │ 1 │ 2 │ 3 │ 4 │ 5 │ 6 │ 7 │    目录大小 = 2^global_depth
                    └─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┘
                      │   │   │   │   │   │   │   │
                      ▼   ▼   │   │   ▼   ▼   │   │
                    ┌─────┐   │   │ ┌─────┐   │   │
                    │Seg A│   │   │ │Seg A│   │   │      多个目录槽可以
                    │ld=2 │   │   │ │ld=2 │   │   │      指向同一 segment
                    └─────┘   ▼   ▼ └─────┘   ▼   ▼
                            ┌─────┐         ┌─────┐
                            │Seg B│         │Seg C│
                            │ld=3 │         │ld=3 │
                            └─────┘         └─────┘

    Segment（段）
    ┌──────────────────────────────────┐
    │ local_depth: 当前段的深度         │
    │ segment_id:  在目录中的起始索引    │
    │ table: ankerl::unordered_dense   │  ← 实际存储键值对
    └──────────────────────────────────┘
```

**两个关键深度值**：
- **Global Depth**：目录级别的深度，决定目录大小（`2^global_depth`）
- **Local Depth**：每个 segment 的深度，决定有多少目录槽指向它

**不变量**：`local_depth ≤ global_depth`

### 2.2 索引计算：使用哈希值的高位

```cpp
uint64_t GetSegmentIndex(const K& key) const {
    uint64_t hash = Hash(key);  // 64 位哈希值
    if (global_depth_ == 0) return 0;
    return hash >> (64 - global_depth_);  // 取高位作为索引
}
```

**为什么用高位而不是低位？**

```
哈希值（64 位）:
┌────────────────────────────────────────────────────────┐
│ 高位 (用于目录索引)          低位 (用于 segment 内部)    │
│ ◄── global_depth 位 ──►                               │
└────────────────────────────────────────────────────────┘

扩容时 global_depth 增加 1：
  扩容前: 取高 2 位 → 索引范围 [0, 3]
  扩容后: 取高 3 位 → 索引范围 [0, 7]

  原来索引为 01 的元素，现在可能是 010 或 011
  → 自然地分为两组，无需重新计算哈希
```

高位索引在扩容时具有天然的稳定性：旧索引是新索引的前缀。

**示例**：

```
global_depth = 3
hash = 0xA7B3C4D5E6F70812

索引计算:
  hash >> (64 - 3) = hash >> 61
  0xA7B3... 的最高 3 位 = 0b101 = 5

  → 访问 directory[5] 指向的 segment
```

## 3. 扩容机制

### 3.1 何时触发扩容

```cpp
bool NeedSplit(uint32_t seg_id) const {
    return segment->table.size() >= max_segment_size_ * kSplitThreshold;
}
// kSplitThreshold = 0.8  →  segment 容量达到 80% 时触发
```

### 3.2 扩容的两种情况

**情况一：local_depth < global_depth（简单分裂）**

目录中有多余的槽可以使用，只需分裂 segment 并更新目录指针：

```
扩容前 (global_depth=3):
  目录: [0:A] [1:A] [2:B] [3:B] [4:A] [5:A] [6:B] [7:B]
                                  ↑  ↑
                            Segment A (ld=2)
                            覆盖索引 0,1,4,5

Segment A 需要分裂：

Step 1: 计算分裂参数
  chunk_size = 2^(global_depth - local_depth) = 2^(3-2) = 2
  start_idx = 0（第一组: 0,1）
  chunk_mid = 0 + 2/2 = 1

Step 2: 创建新 Segment A'
  local_depth = 3（原始的 2 + 1）

Step 3: 重分布元素
  对 Segment A 中的每个元素重新计算索引（取高 3 位）
  索引的第 3 位 = 0 → 留在 A
  索引的第 3 位 = 1 → 移到 A'

Step 4: 更新目录
  目录: [0:A] [1:A'] [2:B] [3:B] [4:A] [5:A'] [6:B] [7:B]

扩容后:
  Segment A  (ld=3): 覆盖索引 0, 4
  Segment A' (ld=3): 覆盖索引 1, 5
```

**情况二：local_depth == global_depth（需要先扩展目录）**

```
扩容前 (global_depth=2):
  目录: [0:A] [1:A] [2:B] [3:B]
  所有 segment 的 local_depth = 2 = global_depth

Segment B 需要分裂，但 ld == gd，无法分裂

Step 1: 目录翻倍
  global_depth: 2 → 3
  目录大小: 4 → 8
  每个旧槽扩展为 2 个新槽

  原目录: [0:A] [1:A]    [2:B] [3:B]
  新目录: [0:A] [1:A] [2:A] [3:A] [4:B] [5:B] [6:B] [7:B]

Step 2: 现在 Segment B 的 local_depth(2) < global_depth(3)
  可以执行情况一的简单分裂

Step 3: 分裂 Segment B
  目录: [0:A] [1:A] [2:A] [3:A] [4:B] [5:B] [6:B'] [7:B']
```

### 3.3 目录翻倍的细节

目录翻倍是一个纯指针操作，不涉及任何数据迁移：

```cpp
void ExpandDirectory() {
    uint64_t old_size = segment_directory_.size();
    segment_directory_.resize(old_size * 2);

    // 从后往前，每个旧槽"展开"为 2 个新槽
    for (int64_t i = old_size - 1; i >= 0; --i) {
        uint64_t offs = i * 2;
        segment_directory_[offs]     = segment_directory_[i];
        segment_directory_[offs + 1] = segment_directory_[i];
    }
    global_depth_++;
}
```

**关键点**：目录翻倍只是复制 `shared_ptr`（指针），不复制任何数据。在百万级键的场景下，目录可能只有几百个槽，翻倍的成本微乎其微。

## 4. 遍历与计数

### 4.1 避免重复计数

由于多个目录槽可能指向同一个 segment，遍历时需要跳过重复：

```cpp
size_t NextSeg(size_t sid) const {
    uint32_t chunk_size = 1 << (global_depth_ - segment_directory_[sid]->local_depth);
    return sid + chunk_size;  // 跳过所有指向同一 segment 的槽
}

// 使用方式
size_t total = 0;
for (size_t i = 0; i < directory_size; i = NextSeg(i)) {
    total += segment_directory_[i]->table.size();
}
```

**示例**：

```
目录: [0:A] [1:A] [2:B] [3:C]
       ↓     ↓     ↓     ↓
      ld=1  ld=1  ld=2  ld=2
      gd=2  gd=2  gd=2  gd=2

遍历: i=0 → Seg A (chunk=2^(2-1)=2, next=2)
      i=2 → Seg B (chunk=2^(2-2)=1, next=3)
      i=3 → Seg C (chunk=2^(2-2)=1, next=4)
      i=4 → 结束

正确遍历了 3 个 segment，不会重复计数 A
```

## 5. 完整操作示例

### 5.1 Insert 流程

```
Insert(key="user:42", value="Alice")
    │
    ▼
① 计算哈希: hash = Hash("user:42") = 0xC3A5...
    │
    ▼
② 计算目录索引: idx = hash >> (64 - global_depth)
   假设 global_depth=3, idx = 0xC3A5... >> 61 = 6
    │
    ▼
③ 找到 segment: seg = directory[6]
    │
    ▼
④ 插入到 segment 的内部哈希表: seg->table.insert(key, value)
    │
    ▼
⑤ 检查是否需要分裂: seg->table.size() >= threshold?
    │
    ├── 否 → 完成
    └── 是 → SplitSegment(6) → 可能触发 ExpandDirectory
```

### 5.2 Find 流程

```
Find(key="user:42")
    │
    ▼
① hash = Hash("user:42")
    │
    ▼
② idx = hash >> (64 - global_depth)
    │
    ▼
③ seg = directory[idx]
    │
    ▼
④ return seg->table.find(key)   // O(1)
```

查找操作始终是 O(1)，且只访问一个 segment。

## 6. 复杂度分析

| 操作 | 平均 | 最坏 | 备注 |
|------|------|------|------|
| Insert | O(1) | O(k) | k = segment 中的元素数（分裂时） |
| Find | O(1) | O(1) | 一次目录查找 + 一次 segment 内查找 |
| Erase | O(1) | O(1) | |
| SplitSegment | O(k) | O(k) | k = 被分裂 segment 的元素数 |
| ExpandDirectory | O(d) | O(d) | d = 目录大小（纯指针操作） |
| Size | O(s) | O(s) | s = 实际 segment 数 |

**空间复杂度**：
- 目录：O(2^global_depth) 个指针（通常很小）
- Segments：O(n) 个元素（n = 总元素数）
- 总计：O(n + 2^global_depth)

## 7. DashTable 在 NanoRedis 中的应用

### 7.1 作为主数据表

每个逻辑数据库使用两个 DashTable：

```cpp
class Database {
    // 主数据表：key → value
    DashTable<NanoObj, NanoObj> main_tables_[16];

    // 过期时间表：key → expire_at_ms
    DashTable<NanoObj, int64_t> expire_tables_[16];
};
```

### 7.2 作为 Hash 类型的内部结构

Redis 的 Hash 类型（如 `HSET user:1 name Alice age 30`）内部也使用 DashTable：

```cpp
// Hash 类型的底层存储
NanoObj hash = NanoObj::fromHash();
auto* ht = new DashTable<NanoObj, NanoObj>();
ht->Insert(NanoObj::fromKey("name"), NanoObj("Alice"));
ht->Insert(NanoObj::fromKey("age"), NanoObj("30"));
hash.setObj(ht);
```

### 7.3 线程安全说明

DashTable 本身不是线程安全的，但在 NanoRedis 的 Shared-Nothing 架构下，每个 DashTable 只被一个线程（vCPU）访问，无需加锁。这是架构层面的线程安全——通过消除共享来消除竞争。

## 8. 设计权衡

### 8.1 与 Redis 哈希表的对比

| 特性 | Redis dict | DashTable |
|------|-----------|-----------|
| 算法 | 链地址法 | Extendible Hashing |
| 扩容方式 | 渐进式 rehash（两个表交替） | Segment 分裂（增量扩容） |
| 扩容影响 | 扩容期间查找需查两个表 | 只影响被分裂的 segment |
| 内存开销 | 扩容期间内存翻倍 | 只增加一个 segment |
| 冲突处理 | 链表 | 开地址法（ankerl） |
| 缓存友好性 | 差（链表跳转） | 好（连续内存） |

### 8.2 底层使用 ankerl::unordered_dense

每个 segment 的内部哈希表使用 `ankerl::unordered_dense::map`，这是一个高性能的开地址哈希表：

- **连续内存存储**：所有键值对存储在一个 `std::vector` 中，缓存友好
- **Robin Hood 哈希**：减少查找时的探测次数
- **比 `std::unordered_map` 快 2-3 倍**

### 8.3 Segment 大小的选择

```cpp
constexpr float kSplitThreshold = 0.8f;
```

负载因子 0.8 是空间利用率和性能的平衡点：
- 太小（如 0.5）：频繁分裂，浪费内存
- 太大（如 0.95）：哈希冲突增加，查找变慢
- 0.8：经验上的最佳实践

## 9. 一致性保证

DashTable 维护以下不变量，可用于调试验证：

```
1. global_depth ≤ 64
2. directory_size == 2^global_depth（或 global_depth==0 时为 1）
3. 对所有 segment: local_depth ≤ global_depth
4. 每个 segment 被 2^(global_depth - local_depth) 个目录槽指向
5. 指向同一 segment 的所有目录槽必须是连续的
6. segment_id 等于其在目录中的起始索引
```

这些不变量在 `IsDirectoryConsistent()` 中被完整检查，是单元测试的关键断言。

---

上一篇：[NanoObj：16 字节的通用值对象](1.nano_obj.md)
下一篇：[Shared-Nothing 架构与 Fiber 并发模型](3.shared_nothing.md)
