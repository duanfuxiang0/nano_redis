# DashTable 设计笔记（Extendible Hashing）

DashTable 是 NanoRedis 里的一张可扩展哈希表。它解决的问题很具体：**随着键数量增长，尽量不要做“一次性全表 rehash”**。
实现上采用 Extendible Hashing：用一个 directory（目录）做“索引面”，用 segment（分段）做“数据面”，扩容时只对单个 segment 做 split，并在必要时把 directory 翻倍。

这个设计看起来有点绕，但它的“精巧”在于：directory 只负责“把前缀映射到 segment”，segment 只负责“存数据”；扩容时只动一个 chunk，并且通过增加 `global_depth` 来渐进地细化前缀，而不是把整张表推倒重来。

这篇文档的目标不是复述代码，而是让你看懂三件事：

1. `global_depth / local_depth` 到底是什么意思，为什么 directory 会指向同一个 segment。
2. 一次 `SplitSegment()` 到底做了什么（以及什么时候需要先扩 directory）。
3. 为什么实现里很多遍历都要用 `NextSeg()` 这种“跳着走”的方式。

代码位置：`include/core/dashtable.h` 与 `src/core/dashtable.cc`。

## 0. 先约定一下术语

- **Directory**：`std::vector<std::shared_ptr<Segment>> segment_directory`，长度为 `2^global_depth`（`global_depth == 0` 时长度为 1）。
- **Segment**：真正存数据的容器，内部是 `ankerl::unordered_dense::map`。
- **Directory 槽位（slot）**：directory 的一个下标，比如 `segment_directory[dir_idx]`。
- **别名（alias）**：多个 slot 指向同一个 `Segment`（因此用 `shared_ptr`）。
- `segment_id`：segment 在 directory 中所在 chunk 的起点下标（主要用于 split 过程的重定位，以及 `IsDirectoryConsistent()` 的校验）。

下面这张图是 DashTable 的整体形态（你会在后文多次用它对照）：

```
┌─────────────────────────────────────────────────────────────────┐
│                            DashTable                             │
│                                                                  │
│  Directory: segment_directory (size = 2^global_depth)            │
│  ┌──────┬──────┬──────┬──────┬──────┬──────┬──────┬──────┐      │
│  │  0   │  1   │  2   │  3   │  4   │  5   │  6   │  7   │ ...  │
│  └──┬───┴──┬───┴──┬───┴──┬───┴──┬───┴──┬───┴──┬───┴──┬───┘      │
│     │      │      │      │      │      │      │      │          │
│     ▼      ▼      ▼      ▼      ▼      ▼      ▼      ▼          │
│   ┌────────────────┐   ┌────────────────┐   ┌────────────────┐  │
│   │ Segment A       │   │ Segment B       │   │ Segment C       │  │
│   │ local_depth = ? │   │ local_depth = ? │   │ local_depth = ? │  │
│   │ table: unordered_dense::map           │   │ ...              │  │
│   └────────────────┘   └────────────────┘   └────────────────┘  │
│                                                                  │
│  global_depth = ?                                                │
└─────────────────────────────────────────────────────────────────┘
```

## 1. global_depth / local_depth：不是“越大越好”，而是“区分到哪一位”

DashTable 用 key 的 hash 值做索引，但它不会把 hash 的全部位都拿来做 directory 下标，而是只看前 `global_depth` 位。

- `global_depth`：directory 使用的 hash 前缀长度（位数）。
- `local_depth`：某个 segment 当前使用的 hash 前缀长度（位数）。

直觉上可以这样理解：

- `global_depth` 决定 directory 有多“细”（`2^global_depth` 个槽位）。
- `local_depth` 决定这个 segment 被区分到了哪一位：`local_depth` 越小，说明它还比较“粗”，directory 里会有更多槽位别名到它。

在我们的实现（用 hash 的高位作为索引）中，目录槽位别名关系是连续区间，因此下面这条关系非常关键：

> 当 `global_depth = G`、`local_depth = L` 时，一个 segment 在 directory 中占用的槽位数是 `2^(G - L)`（一段连续区间）。

举个可视化的例子（`global_depth = 3`，directory 长度为 8）：

```
dir idx:  0 1 2 3 4 5 6 7
ptr ->   [A A A A B B C C]

A.local_depth = 1  => 2^(3-1) = 4 个槽位（连续区间 [0,4)）
B.local_depth = 2  => 2^(3-2) = 2 个槽位（连续区间 [4,6)）
C.local_depth = 2  => 2^(3-2) = 2 个槽位（连续区间 [6,8)）
```

这也是 `NextSeg()` 能“跳过去”的原因：当你站在 `dir_idx = 0`，就知道后面还有 3 个槽位指向同一个 A，没必要逐个重复遍历。

## 2. 索引：取 hash 的高位，映射到 directory

`GetSegmentIndex()` 的核心逻辑是：

```cpp
uint64_t hash = ankerl::unordered_dense::hash<K>{}(key);
if (global_depth == 0) {
	return 0;
}
return hash >> (64 - global_depth);
```

这里使用 **hash 的高位**（而不是低位）作为 directory 下标的前缀。好处是：当 `global_depth` 增长时，索引只是“多看一位前缀”，映射规则更稳定，目录区间也更直观。

为了让这件事更像“看得见”，可以把 hash 画成这样：

```
hash (64 bits)
┌───────────────┬───────────────────────────────────────────────┐
│  high bits     │                    remaining bits            │
│  (directory)   │                 (segment internal)           │
└───────────────┴───────────────────────────────────────────────┘
       ↑
       取前 global_depth 位，作为 dir_idx
```

## 3. 插入：先写进去，再决定要不要 split（可能不止一次）

`Insert()` 的代码路径有一个很“工程”的选择：它不预判要不要 split，而是 **先 insert_or_assign**，再用 `NeedSplit()` 检查阈值。

```
Insert(key, value)
  │
  ├─► dir_idx = GetSegmentIndex(key)
  ├─► segment = segment_directory[dir_idx]
  ├─► segment.table.insert_or_assign(key, value)
  │
  └─► while NeedSplit(dir_idx):
         SplitSegment(dir_idx)
         dir_idx = GetSegmentIndex(key)   // directory 可能扩张，必须重算
```

`NeedSplit()` 的判断是基于元素数量的近似负载：

```cpp
segment->table.size() >= max_segment_size * kSplitThreshold
```

其中 `kSplitThreshold = 0.8f`，`max_segment_size` 默认 16（构造函数参数）。

这里需要注意两个容易混淆的点：

1. `max_segment_size` 在当前实现里更像“分裂阈值的尺度”，不是底层容器的严格容量上限。
2. segment 内部使用 `unordered_dense::map`，构造时给了一个初始 bucket 数（`fixed_bucket_count`），并设置了 `table.max_load_factor(1.0f)`；但 split 触发条件不直接依赖 bucket_count。

## 4. SplitSegment：一次 split 分两段，必要时先扩 directory

一次 `SplitSegment(seg_id)` 的目标是：把 `seg_id` 所在的那段连续区间拆成两半，让其中一半继续指向旧 segment，另一半改指向新 segment，并把落在“新半区”的 key 搬过去。

为了描述清楚，我们先把 directory 中指向同一个 segment 的连续区间叫做 **chunk**：

- chunk 的大小：`chunk_size = 2^(global_depth - local_depth)`
- chunk 的起点：`start_idx`（把 `seg_id` 对齐到 chunk 起点）
- chunk 的中点：`chunk_mid = start_idx + chunk_size/2`

实现里对应的计算是（省略类型细节）：

```cpp
chunk_size = 1ULL << (global_depth - source->local_depth);
start_idx = seg_id & (~(chunk_size - 1));
chunk_mid = start_idx + chunk_size / 2;
```

这里能用位运算对齐，依赖一个事实：我们用的是 hash 高位作为索引，所以“同一前缀”的 directory 槽位在数值上就是一段连续区间。

### 4.1 什么时候需要 Directory Expansion

当 `source->local_depth == global_depth` 时，说明 directory 目前已经“没有更多位数”来继续细分这个 segment。
这时先把 directory 翻倍，让 `global_depth++`，相当于“多看一位前缀”。

扩张前后可以这样理解：

```
扩张前 (global_depth = 2, directory size = 4)
idx:    0   1   2   3
ptr:   [A] [B] [C] [D]

扩张后 (global_depth = 3, directory size = 8)
idx:    0   1   2   3   4   5   6   7
ptr:   [A] [A] [B] [B] [C] [C] [D] [D]
```

扩张的本质是：每个旧槽位复制两份，形成新的连续区间。此时除被 split 的 segment 之外，其他 segment 的 `local_depth` 仍然停留在旧值，因此它们会暂时出现“一个 segment 对应两个槽位”的别名关系。

### 4.2 Segment Split 做了什么

扩张（或不需要扩张）之后，真正的 split 分四步：

1. 计算 chunk（`chunk_size/start_idx/chunk_mid`）。
2. 新建 `new_segment`，并把 `source->local_depth++`（两者 local_depth 都会 +1）。
3. 扫一遍 `source` 里的 key，重新计算它们在新 `global_depth` 下的 `new_idx`，把落在上半区的条目移动到 `new_segment`。
4. 更新 directory：把上半区 `[chunk_mid, start_idx + chunk_size)` 的 slot 指向 `new_segment`。

把这一切画成一张“前后对照”的图，通常更好理解：

```
split 前：一个 chunk 指向同一个 source

start_idx                     start_idx + chunk_size
  │                                 │
  ▼                                 ▼
┌───┬───┬───┬───┬───┬───┬───┬───┐
│ S │ S │ S │ S │ S │ S │ S │ S │   (chunk_size 个槽位)
└───┴───┴───┴───┴───┴───┴───┴───┘

split 后：chunk 一分为二

start_idx         chunk_mid         start_idx + chunk_size
  │                  │                      │
  ▼                  ▼                      ▼
┌───┬───┬───┬───┬───┬───┬───┬───┐
│ S │ S │ S │ S │ N │ N │ N │ N │
└───┴───┴───┴───┴───┴───┴───┴───┘
            ↑              ↑
        source 留下      new_segment 接管
        前半段            后半段
```

这里“前半段/后半段”的判断依据，就是 `new_idx` 是否落在 `[chunk_mid, start_idx + chunk_size)`。

## 5. 走一遍最小示例：从 1 个 segment 开始扩起来

如果你第一次接触 extendible hashing，把它当成“目录不断变细、桶不断拆分”的过程会更自然。

### 5.1 初始状态（默认构造）

默认 `initial_segment_count = 1`：

```
global_depth = 0
directory size = 1

idx: 0
ptr: [A]   (A.local_depth = 0)
```

### 5.2 触发第一次 split：先扩目录，再拆桶

当 A 的元素数量达到阈值时，调用 `SplitSegment(0)`：

1) 因为 `A.local_depth == global_depth == 0`，先扩 directory：

```
global_depth: 0 -> 1

idx: 0 1
ptr: [A A]
```

2) 然后 split chunk `[0,2)`，得到新桶 B：

```
idx: 0 1
ptr: [A B]

A.local_depth = 1
B.local_depth = 1
```

此后 `GetSegmentIndex()` 会取 hash 的最高 1 位，把 key 分到 A 或 B。

### 5.3 下一次扩张：directory 再翻倍

当某个桶再次长到阈值，且它的 `local_depth` 追上 `global_depth`，就会发生同样的“扩目录 + 拆桶”的组合动作。
每次扩目录，directory size 都乘 2，`global_depth` 加 1；每次拆桶，则把某个 chunk 一分为二。

这一节的价值在于：你不用背公式，只要记住“扩目录是为了多看一位前缀，拆桶是为了把 chunk 分成两半”。

## 6. 遍历与统计：为什么要 NextSeg()

由于 directory 会别名同一个 segment，如果你写：

```cpp
for (size_t i = 0; i < segment_directory.size(); ++i) {
	// ...
}
```

你会重复访问同一个 `Segment` 多次，统计会被重复累加，遍历也会变慢。

DashTable 的做法是：从某个 `sid` 出发，直接跳到“下一个 chunk 的起点”：

```cpp
delta = 2^(global_depth - segment_directory[sid]->local_depth)
sid += delta
```

因此：

- `ForEach/Size/BucketCount` 使用 `NextSeg()`，保证每个 segment 只遍历一次。
- `IsDirectoryConsistent()` 会检查 directory 大小是否为 `2^global_depth`、`local_depth` 是否不超过 `global_depth`，以及每个 chunk 的连续槽位是否都指向同一个 segment。

另外，当前实现里的 `SegmentCount()` 返回的是 `segment_directory.size()`（即 directory 槽位数量），不是“唯一 segment 的数量”。如果你关心后者，需要像 `Size()` 一样用 `NextSeg()` 的节奏去数。

## 7. 并发模型（为什么这里可以不加锁）

DashTable 本身不做线程安全保证。
在 NanoRedis 的 shared-nothing 架构里，一个分片的数据结构由归属线程独占访问，DashTable 通常只在这个线程上读写；跨线程的并发控制由更外层的分片/任务队列机制负责。

## 8. 参考

- 本仓库实现：`include/core/dashtable.h`、`src/core/dashtable.cc`
- 底层容器：`include/core/unordered_dense.h`（martinus/unordered_dense 4.8.1）
- Extendible Hashing：Fagin 等人的经典论文（“Extendible Hashing”）
